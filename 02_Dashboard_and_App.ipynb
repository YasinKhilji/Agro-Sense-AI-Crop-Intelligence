{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "uDN2gev_2hSt",
        "outputId": "cf4e2ff6-4837-4597-9c33-c842a079f81e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Data Simulation for All Fields ---\n",
            "âœ… 'advanced_labeled_dataset.csv' loaded successfully.\n",
            "âœ… Simulation complete for 'Field_1'.\n",
            "âœ… Simulation complete for 'Field_2'.\n",
            "âœ… Simulation complete for 'Field_3'.\n",
            "âœ… Simulation complete for 'Field_4'.\n",
            "âœ… Simulation complete for 'Field_5'.\n",
            "âœ… Simulation complete for 'Field_6'.\n",
            "âœ… Simulation complete for 'Field_7'.\n",
            "âœ… Simulation complete for 'Field_8'.\n",
            "âœ… Simulation complete for 'Field_9'.\n",
            "\n",
            "--- SUCCESS ---\n",
            "âœ… New file saved as: hackathon_dataset.csv\n",
            "\n",
            "Here's a preview of your new hackathon dataset (first 5 rows from all fields combined):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Date field_id  ndvi_normalized  Temperature_C  \\\n",
              "0 2019-06-02  Field_1         0.056963      36.880714   \n",
              "1 2019-06-09  Field_1         0.030072      38.038571   \n",
              "2 2019-06-16  Field_1         0.027313      37.856429   \n",
              "3 2019-06-23  Field_1         0.033136      34.162143   \n",
              "4 2019-06-30  Field_1         0.056428      36.359286   \n",
              "\n",
              "   simulated_soil_moisture  simulated_leaf_wetness  \n",
              "0                       70                       0  \n",
              "1                       65                       0  \n",
              "2                       60                      85  \n",
              "3                       55                      85  \n",
              "4                       50                      85  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39eb14e9-10c9-494d-9e28-b10a84849448\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>field_id</th>\n",
              "      <th>ndvi_normalized</th>\n",
              "      <th>Temperature_C</th>\n",
              "      <th>simulated_soil_moisture</th>\n",
              "      <th>simulated_leaf_wetness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-06-02</td>\n",
              "      <td>Field_1</td>\n",
              "      <td>0.056963</td>\n",
              "      <td>36.880714</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-06-09</td>\n",
              "      <td>Field_1</td>\n",
              "      <td>0.030072</td>\n",
              "      <td>38.038571</td>\n",
              "      <td>65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-06-16</td>\n",
              "      <td>Field_1</td>\n",
              "      <td>0.027313</td>\n",
              "      <td>37.856429</td>\n",
              "      <td>60</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-06-23</td>\n",
              "      <td>Field_1</td>\n",
              "      <td>0.033136</td>\n",
              "      <td>34.162143</td>\n",
              "      <td>55</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-06-30</td>\n",
              "      <td>Field_1</td>\n",
              "      <td>0.056428</td>\n",
              "      <td>36.359286</td>\n",
              "      <td>50</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39eb14e9-10c9-494d-9e28-b10a84849448')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39eb14e9-10c9-494d-9e28-b10a84849448 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39eb14e9-10c9-494d-9e28-b10a84849448');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6cb51c1c-3c0e-47a0-82b1-f0210c2d0bc0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cb51c1c-3c0e-47a0-82b1-f0210c2d0bc0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6cb51c1c-3c0e-47a0-82b1-f0210c2d0bc0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(f\\\"\\\\nAn unexpected error occurred: {e}\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2019-06-02 00:00:00\",\n        \"max\": \"2019-06-30 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2019-06-09 00:00:00\",\n          \"2019-06-30 00:00:00\",\n          \"2019-06-16 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"field_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Field_1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ndvi_normalized\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014673103686327038,\n        \"min\": 0.0273127898799094,\n        \"max\": 0.0569627516857743,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0300720154500044\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature_C\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.5580703659675053,\n        \"min\": 34.16214285714286,\n        \"max\": 38.03857142857142,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          38.03857142857142\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"simulated_soil_moisture\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 50,\n        \"max\": 70,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"simulated_leaf_wetness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 0,\n        \"max\": 85,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"--- Starting Data Simulation for All Fields ---\")\n",
        "\n",
        "# Load the dataset we created in the OELP project\n",
        "try:\n",
        "    df_full = pd.read_csv('advanced_labeled_dataset.csv')\n",
        "    print(\"âœ… 'advanced_labeled_dataset.csv' loaded successfully.\")\n",
        "\n",
        "    df_full['Date'] = pd.to_datetime(df_full['Date'])\n",
        "\n",
        "    simulated_data_frames = []\n",
        "    unique_field_ids = df_full['field_id'].unique()\n",
        "\n",
        "    for field_id in unique_field_ids:\n",
        "        df_field = df_full[df_full['field_id'] == field_id].copy()\n",
        "        df_field = df_field.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "        if len(df_field) == 0:\n",
        "            print(f\"âš ï¸ No data for field '{field_id}', skipping simulation.\")\n",
        "            continue\n",
        "\n",
        "        # 2. Simulate Soil Moisture and Leaf Wetness\n",
        "        # Initialize for each field\n",
        "        soil_moisture = [70]  # Start with a healthy 70%\n",
        "        leaf_wetness = [0]    # Start with dry leaves\n",
        "\n",
        "        # Ensure we have enough data points to simulate (at least 1 for initial values)\n",
        "        if len(df_field) > 1:\n",
        "            for i in range(1, len(df_field)):\n",
        "                prev_sm = soil_moisture[-1]\n",
        "                temp = df_field['Temperature_C'].iloc[i]\n",
        "                ndvi = df_field['ndvi_normalized'].iloc[i]\n",
        "\n",
        "                # Rules for Soil Moisture\n",
        "                precip_chance = np.random.rand() < 0.1\n",
        "                if precip_chance and 0.2 < ndvi < 0.8:\n",
        "                    new_sm = min(100, prev_sm + 30)\n",
        "                elif temp > 25:\n",
        "                    new_sm = max(0, prev_sm - 5)\n",
        "                else:\n",
        "                    new_sm = max(0, prev_sm - 2)\n",
        "                soil_moisture.append(new_sm)\n",
        "\n",
        "                # Rules for Leaf Wetness\n",
        "                humidity_chance = np.random.rand() < 0.4\n",
        "                if precip_chance:\n",
        "                    leaf_wetness.append(100)\n",
        "                elif humidity_chance:\n",
        "                    leaf_wetness.append(85)\n",
        "                else:\n",
        "                    leaf_wetness.append(0)\n",
        "        elif len(df_field) == 1:\n",
        "            # If only one data point, just use initial values\n",
        "            soil_moisture = [70]\n",
        "            leaf_wetness = [0]\n",
        "\n",
        "\n",
        "        df_field['simulated_soil_moisture'] = soil_moisture[:len(df_field)] # Slice to match df_field length\n",
        "        df_field['simulated_leaf_wetness'] = leaf_wetness[:len(df_field)] # Slice to match df_field length\n",
        "        simulated_data_frames.append(df_field)\n",
        "        print(f\"âœ… Simulation complete for '{field_id}'.\")\n",
        "\n",
        "    if not simulated_data_frames:\n",
        "        print(\"âŒ No data frames were simulated. Check 'advanced_labeled_dataset.csv' content.\")\n",
        "        raise ValueError(\"No data to save after simulation.\")\n",
        "\n",
        "    # Concatenate all simulated data into one DataFrame\n",
        "    df_final = pd.concat(simulated_data_frames, ignore_index=True)\n",
        "\n",
        "    # 3. Save the final dataset\n",
        "    output_filename = 'hackathon_dataset.csv'\n",
        "    df_final.to_csv(output_filename, index=False)\n",
        "\n",
        "    print(f\"\\n--- SUCCESS ---\")\n",
        "    print(f\"âœ… New file saved as: {output_filename}\")\n",
        "    print(\"\\nHere's a preview of your new hackathon dataset (first 5 rows from all fields combined):\")\n",
        "    display(df_final[['Date', 'field_id', 'ndvi_normalized', 'Temperature_C', 'simulated_soil_moisture', 'simulated_leaf_wetness']].head())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"\\nâŒ ERROR: 'advanced_labeled_dataset.csv' not found. Please upload the file before running this cell.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn unexpected error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ydIoEZp2wGp",
        "outputId": "2049bb4b-b616-405f-9411-405dcf794875"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value counts for 'simulated_leaf_wetness':\n",
            "simulated_leaf_wetness\n",
            "0      795\n",
            "85     534\n",
            "100    147\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset we just created\n",
        "hackathon_df = pd.read_csv('hackathon_dataset.csv')\n",
        "\n",
        "# Count the occurrences of each value in the column\n",
        "print(\"Value counts for 'simulated_leaf_wetness':\")\n",
        "print(hackathon_df['simulated_leaf_wetness'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9PqhbG6P2y8B",
        "outputId": "2bb8ba21-3f6d-4c4d-ab3b-6e590e0efae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Loading and Initial Setup ---\n",
            "âœ… 'hackathon_dataset.csv' loaded successfully.\n",
            "\n",
            "--- Step 2: Preparing Data for LSTM ---\n",
            "âœ… Data prepared with 1177 training sequences.\n",
            "\n",
            "--- Step 3: Building the LSTM Model ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             â”‚        \u001b[38;5;34m11,400\u001b[0m â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚           \u001b[38;5;34m153\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,400</span> â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">153</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,553\u001b[0m (45.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,553</span> (45.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,553\u001b[0m (45.13 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,553</span> (45.13 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Step 4: Training the Model (this may take a minute) ---\n",
            "Epoch 1/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.4994 - loss: 1.0133 - val_accuracy: 0.6780 - val_loss: 0.6988\n",
            "Epoch 2/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7171 - loss: 0.6424 - val_accuracy: 0.7373 - val_loss: 0.6595\n",
            "Epoch 3/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7055 - loss: 0.6798 - val_accuracy: 0.7542 - val_loss: 0.6182\n",
            "Epoch 4/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.7205 - loss: 0.6406 - val_accuracy: 0.7881 - val_loss: 0.5856\n",
            "Epoch 5/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7634 - loss: 0.5397 - val_accuracy: 0.8051 - val_loss: 0.5513\n",
            "Epoch 6/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7835 - loss: 0.5273 - val_accuracy: 0.7797 - val_loss: 0.5449\n",
            "Epoch 7/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7848 - loss: 0.5138 - val_accuracy: 0.7966 - val_loss: 0.4586\n",
            "Epoch 8/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8213 - loss: 0.4493 - val_accuracy: 0.8475 - val_loss: 0.4328\n",
            "Epoch 9/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8399 - loss: 0.4264 - val_accuracy: 0.8475 - val_loss: 0.4185\n",
            "Epoch 10/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8351 - loss: 0.4311 - val_accuracy: 0.7881 - val_loss: 0.5264\n",
            "Epoch 11/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8250 - loss: 0.4522 - val_accuracy: 0.7881 - val_loss: 0.4704\n",
            "Epoch 12/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8307 - loss: 0.4339 - val_accuracy: 0.7881 - val_loss: 0.4504\n",
            "Epoch 13/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8330 - loss: 0.4350 - val_accuracy: 0.8305 - val_loss: 0.4246\n",
            "Epoch 14/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8160 - loss: 0.4396 - val_accuracy: 0.8136 - val_loss: 0.4340\n",
            "Epoch 15/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.3619 - val_accuracy: 0.8390 - val_loss: 0.4126\n",
            "Epoch 16/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8298 - loss: 0.4358 - val_accuracy: 0.8559 - val_loss: 0.3996\n",
            "Epoch 17/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8352 - loss: 0.4070 - val_accuracy: 0.8220 - val_loss: 0.4342\n",
            "Epoch 18/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.3885 - val_accuracy: 0.8390 - val_loss: 0.4215\n",
            "Epoch 19/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8372 - loss: 0.3867 - val_accuracy: 0.8475 - val_loss: 0.4212\n",
            "Epoch 20/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8374 - loss: 0.4017 - val_accuracy: 0.8390 - val_loss: 0.4202\n",
            "Epoch 21/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8529 - loss: 0.4015 - val_accuracy: 0.8390 - val_loss: 0.4345\n",
            "Epoch 22/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8494 - loss: 0.3881 - val_accuracy: 0.8390 - val_loss: 0.4414\n",
            "Epoch 23/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8544 - loss: 0.3610 - val_accuracy: 0.8220 - val_loss: 0.4256\n",
            "Epoch 24/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8714 - loss: 0.3688 - val_accuracy: 0.8136 - val_loss: 0.4631\n",
            "Epoch 25/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8510 - loss: 0.4012 - val_accuracy: 0.8390 - val_loss: 0.4123\n",
            "Epoch 26/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8676 - loss: 0.3782 - val_accuracy: 0.8305 - val_loss: 0.4376\n",
            "Epoch 27/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8634 - loss: 0.3518 - val_accuracy: 0.8220 - val_loss: 0.4200\n",
            "Epoch 28/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8567 - loss: 0.3694 - val_accuracy: 0.8305 - val_loss: 0.4263\n",
            "Epoch 29/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8318 - loss: 0.3953 - val_accuracy: 0.8390 - val_loss: 0.4075\n",
            "Epoch 30/30\n",
            "\u001b[1m133/133\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8662 - loss: 0.3532 - val_accuracy: 0.8305 - val_loss: 0.4312\n",
            "\n",
            "âœ… Model training complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy on Test Data: 83.39%\n",
            "\n",
            "--- Step 5: Saving the Model ---\n",
            "âœ… Model saved to 'crop_stage_lstm_model.h5'. We will use this file in our dashboard.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "print(\"--- Step 1: Loading and Initial Setup ---\")\n",
        "\n",
        "# Load the dataset we created yesterday\n",
        "try:\n",
        "    df = pd.read_csv('hackathon_dataset.csv')\n",
        "    print(\"âœ… 'hackathon_dataset.csv' loaded successfully.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ ERROR: 'hackathon_dataset.csv' not found. Please run the previous data simulation step.\")\n",
        "else:\n",
        "    # --- Step 2: Prepare Data for LSTM ---\n",
        "    print(\"\\n--- Step 2: Preparing Data for LSTM ---\")\n",
        "\n",
        "    # Select features for the model\n",
        "    features = ['ndvi_normalized', 'evi_normalized', 'savi_normalized',\n",
        "                'Temperature_C', 'simulated_soil_moisture', 'simulated_leaf_wetness']\n",
        "    target = 'growth_stage'\n",
        "\n",
        "    # Scale the features to be between 0 and 1\n",
        "    scaler = MinMaxScaler()\n",
        "    df[features] = scaler.fit_transform(df[features])\n",
        "\n",
        "    # Encode the text labels into numbers (e.g., Vegetative -> 2)\n",
        "    encoder = LabelEncoder()\n",
        "    df[target] = encoder.fit_transform(df[target])\n",
        "\n",
        "    # Create sequences\n",
        "    # We will use the last 4 weeks of data (sequence_length) to predict the next stage\n",
        "    sequence_length = 4\n",
        "    X, y = [], []\n",
        "    for i in range(len(df) - sequence_length):\n",
        "        X.append(df[features].iloc[i:i + sequence_length].values)\n",
        "        y.append(df[target].iloc[i + sequence_length])\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(f\"âœ… Data prepared with {len(X_train)} training sequences.\")\n",
        "\n",
        "    # --- Step 3: Build the LSTM Model ---\n",
        "    print(\"\\n--- Step 3: Building the LSTM Model ---\")\n",
        "\n",
        "    num_classes = len(np.unique(y)) # Get the number of unique stages\n",
        "\n",
        "    model = Sequential([\n",
        "        LSTM(50, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    # --- Step 4: Train the Model ---\n",
        "    print(\"\\n--- Step 4: Training the Model (this may take a minute) ---\")\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=30, # We'll train for 30 cycles\n",
        "        batch_size=8,\n",
        "        validation_split=0.1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\nâœ… Model training complete!\")\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\nModel Accuracy on Test Data: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    # --- Step 5: Save the Trained Model ---\n",
        "    print(\"\\n--- Step 5: Saving the Model ---\")\n",
        "    model_filename = 'crop_stage_lstm_model.h5'\n",
        "    model.save(model_filename)\n",
        "    print(f\"âœ… Model saved to '{model_filename}'. We will use this file in our dashboard.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxLkRaTlk2sL",
        "outputId": "4b280232-0212-42ed-c1d1-d4f5208b5feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading dataset for diagnosis logic ---\n",
            "âœ… 'hackathon_dataset.csv' loaded.\n",
            "\n",
            "--- Running a demonstration of the diagnosis logic ---\n",
            "\n",
            "Analyzing data up to week 20 (2019-10-13)...\n",
            "Alert Found: ğŸ’§ Drought Stress Alert: Soil moisture has been critically low for the past 3 weeks.\n",
            "Alert Found: ğŸ„ High Fungal Disease Risk: Conditions have been favorable for fungal growth due to prolonged leaf wetness.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"--- Loading dataset for diagnosis logic ---\")\n",
        "try:\n",
        "    df = pd.read_csv('hackathon_dataset.csv')\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    print(\"âœ… 'hackathon_dataset.csv' loaded.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"âŒ ERROR: 'hackathon_dataset.csv' not found. Please run the data simulation step first.\")\n",
        "else:\n",
        "    # --- Function 1: Diagnose Drought Stress ---\n",
        "    def diagnose_drought_stress(data_sequence, moisture_threshold=25, days_threshold=3):\n",
        "        \"\"\"\n",
        "        Analyzes the last few days of data to check for drought stress.\n",
        "\n",
        "        Args:\n",
        "            data_sequence (pd.DataFrame): DataFrame with the most recent data.\n",
        "            moisture_threshold (int): The soil moisture % below which the crop is considered stressed.\n",
        "            days_threshold (int): The number of consecutive days of stress needed to trigger an alert.\n",
        "\n",
        "        Returns:\n",
        "            str: An alert message or None.\n",
        "        \"\"\"\n",
        "        # Make sure we have enough data to check\n",
        "        if len(data_sequence) < days_threshold:\n",
        "            return None\n",
        "\n",
        "        # Get the most recent data\n",
        "        recent_data = data_sequence.tail(days_threshold)\n",
        "\n",
        "        # Check if all recent days have been below the moisture threshold\n",
        "        if (recent_data['simulated_soil_moisture'] < moisture_threshold).all():\n",
        "            return f\"ğŸ’§ Drought Stress Alert: Soil moisture has been critically low for the past {days_threshold} weeks.\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    # --- Function 2: Diagnose Fungal Disease Risk ---\n",
        "    def diagnose_fungal_risk(data_sequence, wetness_threshold=80, days_threshold=2):\n",
        "        \"\"\"\n",
        "        Analyzes the last few days of data to check for fungal disease risk.\n",
        "\n",
        "        Args:\n",
        "            data_sequence (pd.DataFrame): DataFrame with the most recent data.\n",
        "            wetness_threshold (int): The leaf wetness % above which conditions are risky.\n",
        "            days_threshold (int): The number of consecutive days of wetness to trigger an alert.\n",
        "\n",
        "        Returns:\n",
        "            str: An alert message or None.\n",
        "        \"\"\"\n",
        "        if len(data_sequence) < days_threshold:\n",
        "            return None\n",
        "\n",
        "        recent_data = data_sequence.tail(days_threshold)\n",
        "\n",
        "        # Check if all recent days have been above the wetness threshold\n",
        "        if (recent_data['simulated_leaf_wetness'] > wetness_threshold).all():\n",
        "            return f\"ğŸ„ High Fungal Disease Risk: Conditions have been favorable for fungal growth due to prolonged leaf wetness.\"\n",
        "\n",
        "        return None\n",
        "\n",
        "    # --- DEMONSTRATION: How to use the functions ---\n",
        "    print(\"\\n--- Running a demonstration of the diagnosis logic ---\")\n",
        "\n",
        "    # Let's pretend today is the 20th week in our dataset\n",
        "    current_week_index = 20\n",
        "    historical_data = df.head(current_week_index) # Get all data up to the current week\n",
        "\n",
        "    # Run the diagnoses\n",
        "    drought_alert = diagnose_drought_stress(historical_data)\n",
        "    fungal_alert = diagnose_fungal_risk(historical_data)\n",
        "\n",
        "    print(f\"\\nAnalyzing data up to week {current_week_index} ({historical_data['Date'].iloc[-1].strftime('%Y-%m-%d')})...\")\n",
        "\n",
        "    if drought_alert:\n",
        "        print(f\"Alert Found: {drought_alert}\")\n",
        "    else:\n",
        "        print(\"âœ… No drought stress detected.\")\n",
        "\n",
        "    if fungal_alert:\n",
        "        print(f\"Alert Found: {fungal_alert}\")\n",
        "    else:\n",
        "        print(\"âœ… No significant fungal disease risk detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "-0fP3XQCn5EM"
      },
      "outputs": [],
      "source": [
        "# Install streamlit for the app and pyngrok to create the public link\n",
        "!pip install -q streamlit pyngrok\n",
        "\n",
        "# Import the ngrok library\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# --- IMPORTANT ---\n",
        "# Paste your ngrok authtoken here\n",
        "authtoken = \"32zkA4NU6alzhZzMhAwGrbu53lM_3He8Njs98urKyqTGa1EQ9\"\n",
        "conf.get_default().auth_token = authtoken"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c1541a3",
        "outputId": "26b48e20-de44-463f-9d8d-eb90f1c5fa92"
      },
      "source": [
        "import ee\n",
        "\n",
        "# Authenticate Earth Engine. This will open a browser window for you to log in.\n",
        "ee.Authenticate()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20688478",
        "outputId": "973b2b5a-d6d3-4fc4-849c-a17762618ccd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "# This %%writefile command MUST be the first line in the cell\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "import plotly.express as px\n",
        "import ee\n",
        "import requests # Import requests for downloading images\n",
        "import os       # Import os for path manipulation\n",
        "\n",
        "# --- LLM Imports and Configuration ---\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "\n",
        "# NOTE: You must replace 'YOUR_GEMINI_API_KEY' with your actual API key.\n",
        "# It's recommended to use Streamlit Secrets for production apps.\n",
        "# For this prototype, we're hardcoding it using the one from the notebook.\n",
        "API_KEY = \"AIzaSyBW2epZ1GzjM0XPZ_Oyud-4nLR6hl7BYI4\" # Using the API key you confirmed works\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# --- Earth Engine Initialization ---\n",
        "@st.cache_resource\n",
        "def initialize_gee():\n",
        "    try:\n",
        "        # ee.Authenticate() # REMOVED: Interactive authentication should be done in a separate cell\n",
        "        ee.Initialize(project='crop-growth-estimation') # Replace with your GEE Project ID\n",
        "\n",
        "        # --- Field Geometries (Example for hackathon_dataset.csv fields) ---\n",
        "        # Moved inside here to ensure EE is initialized before geometries are created\n",
        "        FIELD_GEOMETRIES = {\n",
        "            'Field_1': ee.Geometry.Polygon([[[75.7832, 30.9099], [75.7833, 30.9108], [75.7842, 30.9107], [75.7842, 30.9099]]]),\n",
        "            'Field_2': ee.Geometry.Polygon([[[75.7750, 30.9050], [75.7751, 30.9060], [75.7760, 30.9059], [75.7760, 30.9050]]]),\n",
        "            'Field_3': ee.Geometry.Polygon([[[75.7680, 30.9120], [75.7681, 30.9130], [75.7690, 30.9129], [75.7690, 30.9120]]]),\n",
        "            'Field_4': ee.Geometry.Polygon([[[75.7900, 30.9000], [75.7901, 30.9010], [75.7910, 30.9009], [75.7910, 30.9000]]]),\n",
        "            'Field_5': ee.Geometry.Polygon([[[75.7800, 30.9150], [75.7801, 30.9160], [75.7810, 30.9159], [75.7810, 30.9150]]]),\n",
        "            'Field_6': ee.Geometry.Polygon([[[75.7700, 30.9020], [75.7701, 30.9030], [75.7710, 30.9029], [75.7710, 30.9020]]]),\n",
        "            'Field_7': ee.Geometry.Polygon([[[75.7850, 30.9070], [75.7851, 30.9080], [75.7860, 30.9079], [75.7860, 30.9070]]]),\n",
        "            'Field_8': ee.Geometry.Polygon([[[75.7920, 30.9110], [75.7921, 30.9120], [75.7930, 30.9119], [75.7930, 30.9110]]]),\n",
        "            'Field_9': ee.Geometry.Polygon([[[75.7832, 30.9099], [75.7833, 30.9108], [75.7842, 30.9107], [75.7842, 30.9099]]]) # Re-using Field_1 for now\n",
        "        }\n",
        "        return True, FIELD_GEOMETRIES\n",
        "    except Exception as e:\n",
        "        st.error(f\"Failed to initialize Earth Engine. Please ensure you have authenticated and configured your project. Error: {e}\")\n",
        "        return False, {}\n",
        "\n",
        "# Call GEE initialization once and get geometries\n",
        "gee_initialized, FIELD_GEOMETRIES = initialize_gee()\n",
        "\n",
        "# --- Helper Functions ---\n",
        "def diagnose_drought_stress(data_sequence, moisture_threshold=25, days_threshold=3):\n",
        "    if len(data_sequence) < days_threshold: return None\n",
        "    recent_data = data_sequence.tail(days_threshold)\n",
        "    if (recent_data['simulated_soil_moisture'] < moisture_threshold).all():\n",
        "        return f\"ğŸ’§ Drought Stress Alert: Soil moisture has been critically low for the past {days_threshold} weeks.\"\n",
        "    return None\n",
        "\n",
        "def diagnose_fungal_risk(data_sequence, wetness_threshold=80, days_threshold=2):\n",
        "    if len(data_sequence) < days_threshold: return None\n",
        "    recent_data = data_sequence.tail(days_threshold)\n",
        "    if (recent_data['simulated_leaf_wetness'] > wetness_threshold).all():\n",
        "        return f\"ğŸ„ High Fungal Disease Risk: Conditions have been favorable for fungal growth due to prolonged leaf wetness.\"\n",
        "    return None\n",
        "\n",
        "def get_smart_insight_enhanced(field_id, stage, max_ndvi, weather_condition=None, soil_moisture=None):\n",
        "    \"\"\"\n",
        "    AI-Powered Agronomic Advisory Generator\n",
        "\n",
        "    Integrates LLM reasoning with crop monitoring data to generate actionable insights.\n",
        "    This function bridges the gap between quantitative model outputs (LSTM stage predictions,\n",
        "    XGBoost yield forecasts) and qualitative human-readable advice for farmers.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    field_id : int/str\n",
        "        Unique identifier for the agricultural field\n",
        "    stage : str\n",
        "        Current growth stage from LSTM model (e.g., 'Vegetative', 'Maturity')\n",
        "    max_ndvi : float\n",
        "        Maximum Normalized Difference Vegetation Index (0-1 scale)\n",
        "    weather_condition : str, optional\n",
        "        Current weather pattern (e.g., 'Rainy', 'Sunny', 'Cloudy', 'Storm')\n",
        "    soil_moisture : str, optional\n",
        "        Current soil moisture level (e.g., 'Low', 'Medium', 'High', 'Saturated')\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    str\n",
        "        Natural language advisory report generated by the LLM\n",
        "\n",
        "    Technical Approach:\n",
        "    ------------------\n",
        "    1. Prompt Engineering: Constructs a context-rich prompt with agricultural persona\n",
        "    2. API Integration: Sends structured data to Gemini LLM via REST API\n",
        "    3. Knowledge Synthesis: LLM combines crop science knowledge with input data\n",
        "    4. Output Generation: Returns farmer-friendly recommendations\n",
        "    \"\"\"\n",
        "\n",
        "    model = genai.GenerativeModel('gemini-pro-latest')\n",
        "\n",
        "    prompt_text = f\"\"\"\n",
        "YouAre An Expert Agricultural Scientist Specializing In Rice (Paddy) Cultivation.\n",
        "Analyze the following comprehensive field data for Field {field_id}:\n",
        "\n",
        "**CROP STATUS:**\n",
        "- Growth Stage: {stage}\n",
        "- Maximum NDVI (Vegetation Health Index): {max_ndvi:.2f}\n",
        "\"\"\"\n",
        "\n",
        "    if weather_condition:\n",
        "        prompt_text += f\"\"\"\n",
        "\n",
        "    **WEATHER CONDITIONS:**\n",
        "    - Current Weather: {weather_condition}\n",
        "\"\"\"\n",
        "\n",
        "    if soil_moisture:\n",
        "        prompt_text += f\"\"\"\n",
        "\n",
        "    **SOIL STATUS:**\n",
        "    - Soil Moisture Level: {soil_moisture}\n",
        "\"\"\"\n",
        "\n",
        "    prompt_text += \"\"\"\n",
        "\n",
        "    **REQUIRED ANALYSIS:**\n",
        "    Based on the above data, provide a comprehensive agronomic advisory report. Do NOT include any introductory or concluding phrases like 'Date: [Current Date] Prepared by:' or similar. Only provide the report itself.\n",
        "\n",
        "    1. **Biological Interpretation**: Explain what the current growth stage means biologically for the rice crop\n",
        "    2. **Health Status**: Interpret the NDVI value in terms of crop vigor and canopy coverage\n",
        "\"\"\"\n",
        "\n",
        "    if weather_condition:\n",
        "        prompt_text += \"\"\"\n",
        "    3. **Weather-Based Risks**: Given the current weather, identify any immediate risks:\n",
        "       - Pest/disease outbreak probability\n",
        "       - Waterlogging or drought stress\n",
        "       - Timing considerations for harvest or spraying\n",
        "\"\"\"\n",
        "\n",
        "    if soil_moisture:\n",
        "        prompt_text += \"\"\"\n",
        "    4. **Irrigation & Drainage Advisory**: Based on soil moisture levels:\n",
        "       - Recommend irrigation timing and volume\n",
        "       - Alert about over-watering risks\n",
        "       - Suggest drainage actions if needed\n",
        "\"\"\"\n",
        "\n",
        "    prompt_text += \"\"\"\n",
        "\n",
        "    **OUTPUT FORMAT:**\n",
        "    Provide 3-5 brief, actionable recommendations that a farmer can implement immediately.\n",
        "    Use simple language and focus on practical steps. Directly start with the analysis and recommendations without any preamble.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt_text)\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"API Call Error: {str(e)}\"\n",
        "\n",
        "\n",
        "def generate_dynamic_health_map(field_id, date, project_id='crop-growth-estimation'):\n",
        "    \"\"\"\n",
        "    Fixed version that properly handles Earth Engine ImageCollection validation.\n",
        "    Key fixes:\n",
        "    1. Check collection size using .size().getInfo() before calling .first()\n",
        "    2. Validate image by trying to access its ID before using .select()\n",
        "    3. Wrap band selection in try-except for additional safety\n",
        "    \"\"\"\n",
        "    if not gee_initialized:\n",
        "        st.warning(\"Earth Engine not initialized. Cannot generate dynamic map.\")\n",
        "        return None\n",
        "\n",
        "    field_geom = FIELD_GEOMETRIES.get(field_id)\n",
        "    if not field_geom:\n",
        "        st.warning(f\"No geometry found for field '{field_id}'. Cannot generate map.\")\n",
        "        return None\n",
        "\n",
        "    date_str = date.strftime('%Y-%m-%d')\n",
        "    image_filename = f\"dynamic_health_map_{field_id}_{date_str}.png\"\n",
        "\n",
        "    # Check if image already exists\n",
        "    if os.path.exists(image_filename):\n",
        "        return image_filename\n",
        "\n",
        "    def validate_and_get_image(collection):\n",
        "        \"\"\"Helper function to validate and get image from collection\"\"\"\n",
        "        try:\n",
        "            collection_size = collection.size().getInfo()\n",
        "            if collection_size == 0:\n",
        "                return None\n",
        "\n",
        "            image = collection.sort('system:time_start', False).first()\n",
        "\n",
        "            # Validate image by checking if it has bands and an ID\n",
        "            try:\n",
        "                image_info = image.getInfo()\n",
        "                if image_info is None:\n",
        "                    return None\n",
        "\n",
        "                # Check if image has required bands (B4 and B8 for NDVI)\n",
        "                if 'bands' not in image_info or len(image_info['bands']) == 0:\n",
        "                    return None\n",
        "\n",
        "                band_names = [band['id'] for band in image_info.get('bands', [])]\n",
        "                if 'B4' not in band_names or 'B8' not in band_names:\n",
        "                    return None\n",
        "\n",
        "                # Try to get image ID to ensure it's valid\n",
        "                try:\n",
        "                    image_id = image.get('system:id').getInfo()\n",
        "                    if not image_id:\n",
        "                        return None\n",
        "                except:\n",
        "                    # If we can't get ID, still proceed if bands are valid\n",
        "                    pass\n",
        "\n",
        "                return image\n",
        "            except (ee.EEException, Exception) as e:\n",
        "                return None\n",
        "        except (ee.EEException, Exception) as e:\n",
        "            return None\n",
        "\n",
        "    try:\n",
        "        # --- First attempt: Exact date search ---\n",
        "        # GEE filterDate uses exclusive end date, so add one day\n",
        "        end_date_exact = ee.Date(date_str).advance(1, 'day')\n",
        "\n",
        "        s2_collection_exact = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\\\n",
        "                            .filterBounds(field_geom)\\\n",
        "                            .filterDate(date_str, end_date_exact)\\\n",
        "                            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
        "\n",
        "        image = validate_and_get_image(s2_collection_exact)\n",
        "\n",
        "        if image is None:\n",
        "            st.warning(f\"No clear Sentinel-2 image found for {field_id} on exact date {date_str}. Expanding search to +/- 7 days...\")\n",
        "            # --- Second attempt: Expanded date search (+/- 7 days) ---\n",
        "            start_date_expanded = ee.Date(date_str).advance(-7, 'day')\n",
        "            end_date_expanded = ee.Date(date_str).advance(8, 'day') # +8 days from start = 7 days past selected_date\n",
        "\n",
        "            s2_collection_expanded = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\\\n",
        "                                    .filterBounds(field_geom)\\\n",
        "                                    .filterDate(start_date_expanded, end_date_expanded)\\\n",
        "                                    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))  # Slightly relaxed cloud filter\n",
        "\n",
        "            image = validate_and_get_image(s2_collection_expanded)\n",
        "\n",
        "            if image is None:\n",
        "                st.warning(f\"Still no clear Sentinel-2 image found for {field_id} within +/- 7 days of {date_str}. Please try a different date.\")\n",
        "                return None\n",
        "\n",
        "        # Calculate NDVI (B8 is NIR, B4 is Red for Sentinel-2)\n",
        "        try:\n",
        "            nir = image.select('B8').divide(10000)\n",
        "            red = image.select('B4').divide(10000)\n",
        "            ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
        "        except ee.EEException as e:\n",
        "            st.error(f\"Error calculating NDVI: {e}. The image may not have the required bands.\")\n",
        "            return None\n",
        "\n",
        "        # Health classification based on NDVI\n",
        "        # 1: Stressed (Red), 2: Moderate (Yellow), 3: Healthy (Green)\n",
        "        health_map = ee.Image(0).clip(field_geom)\n",
        "        health_map = health_map.where(ndvi.lt(0.25), 1)  # Stressed\n",
        "        health_map = health_map.where(ndvi.gte(0.25).And(ndvi.lt(0.5)), 2)  # Moderate\n",
        "        health_map = health_map.where(ndvi.gte(0.5), 3)  # Healthy\n",
        "\n",
        "        palette = ['#d73027', '#fee08b', '#1a9850']  # Red, Yellow, Green\n",
        "        vis_params = {\n",
        "            'min': 1,\n",
        "            'max': 3,\n",
        "            'palette': palette\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Generate a thumbnail URL\n",
        "            thumb_url = health_map.getThumbUrl({\n",
        "                'min': vis_params['min'],\n",
        "                'max': vis_params['max'],\n",
        "                'palette': vis_params['palette'],\n",
        "                'dimensions': 512, # px\n",
        "                'format': 'png',\n",
        "                'region': field_geom  # Added region parameter for better clipping\n",
        "            })\n",
        "\n",
        "            # Download the image\n",
        "            response = requests.get(thumb_url, stream=True)\n",
        "            response.raise_for_status() # Raise an exception for HTTP errors\n",
        "\n",
        "            with open(image_filename, 'wb') as out_file:\n",
        "                out_file.write(response.content)\n",
        "\n",
        "            return image_filename\n",
        "\n",
        "        except ee.EEException as e:\n",
        "            st.error(f\"Earth Engine image generation error: {e}\")\n",
        "            return None\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            st.error(f\"Failed to download map image: {e}\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            st.error(f\"An unexpected error occurred during map generation: {e}\")\n",
        "            import traceback\n",
        "            st.error(f\"Error details: {traceback.format_exc()}\")\n",
        "            return None\n",
        "\n",
        "    except ee.EEException as e:\n",
        "        st.error(f\"Earth Engine error: {e}\")\n",
        "        return None\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        st.error(f\"Failed to download map image: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        st.error(f\"An unexpected error occurred during map generation: {e}\")\n",
        "        import traceback\n",
        "        st.error(f\"Error details: {traceback.format_exc()}\")\n",
        "        return None\n",
        "\n",
        "# --- Main App ---\n",
        "st.set_page_config(page_title=\"Agro-Sense AI\", layout=\"wide\")\n",
        "st.title(\"ğŸŒ¾ Agro-Sense AI: Smart Crop Monitoring\")\n",
        "st.write(\"This dashboard provides a real-time analysis of crop health using our 'Smart Diagnosis' engine.\")\n",
        "\n",
        "# --- Load Data and Model ---\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df = pd.read_csv('hackathon_dataset.csv')\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "    return df\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    model = tf.keras.models.load_model('crop_stage_lstm_model.h5')\n",
        "    return model\n",
        "\n",
        "df_full = load_data() # Load the full dataset first\n",
        "model = load_model()\n",
        "\n",
        "# --- Sidebar ---\n",
        "st.sidebar.header(\"Field Selection\")\n",
        "unique_field_ids = df_full['field_id'].unique().tolist() # Extract unique field IDs\n",
        "selected_field = st.sidebar.selectbox(\"Select a field to analyze:\", unique_field_ids)\n",
        "\n",
        "# Filter the DataFrame based on the selected field\n",
        "df_filtered_by_field = df_full[df_full['field_id'] == selected_field].copy()\n",
        "\n",
        "# Add Date Selection\n",
        "st.sidebar.header(\"Date Selection\")\n",
        "max_date_for_field = df_filtered_by_field['Date'].max()\n",
        "selected_date = st.sidebar.date_input(\n",
        "    \"Select analysis date:\",\n",
        "    value=max_date_for_field,\n",
        "    min_value=df_filtered_by_field['Date'].min(),\n",
        "    max_value=max_date_for_field\n",
        ")\n",
        "\n",
        "st.sidebar.info(\"This prototype uses a combination of satellite, weather, and simulated IoT data.\")\n",
        "\n",
        "# --- Sidebar controls for new environmental factor trend plot ---\n",
        "st.sidebar.header(\"Environmental Factors Trend Controls\")\n",
        "show_environmental_factors_trend = st.sidebar.checkbox('Show Environmental Factors Trend', value=False)\n",
        "environmental_factors_options = ['Temperature_C', 'simulated_soil_moisture', 'simulated_leaf_wetness']\n",
        "selected_environmental_factors = st.sidebar.multiselect(\n",
        "    \"Select environmental factors to display:\",\n",
        "    options=environmental_factors_options,\n",
        "    default=['Temperature_C', 'simulated_soil_moisture'] if show_environmental_factors_trend else []\n",
        ")\n",
        "\n",
        "\n",
        "# Filter data again based on the selected date (data up to selected_date)\n",
        "df = df_filtered_by_field[df_filtered_by_field['Date'] <= pd.to_datetime(selected_date)].copy()\n",
        "\n",
        "# --- Preprocess Data for Prediction ---\n",
        "features = ['ndvi_normalized', 'evi_normalized', 'savi_normalized',\n",
        "            'Temperature_C', 'simulated_soil_moisture', 'simulated_leaf_wetness']\n",
        "target = 'growth_stage'\n",
        "scaler = MinMaxScaler()\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Check if there's enough data for the selected field and date range for scaling and encoding\n",
        "# Ensure there are at least 2 unique target values for LabelEncoder if it's new data\n",
        "if not df.empty and len(df[target].unique()) > 1:\n",
        "    # Fit scaler and encoder on data up to the selected date\n",
        "    scaler.fit(df[features])\n",
        "    df_scaled_data = scaler.transform(df[features])\n",
        "    encoder.fit(df[target])\n",
        "else:\n",
        "    df_scaled_data = np.empty((0, len(features)))\n",
        "\n",
        "# --- Make Predictions and Diagnoses ---\n",
        "prediction_decoded = \"Not enough data or unique stages for prediction\"\n",
        "drought_alert = None\n",
        "fungal_alert = None\n",
        "sequence_length = 4\n",
        "\n",
        "# Ensure there's enough data for sequence_length after filtering by date\n",
        "if len(df) >= sequence_length and len(df[target].unique()) > 1:\n",
        "    # Use the last 'sequence_length' records from the data *up to the selected date*\n",
        "    last_sequence_data = df.tail(sequence_length)\n",
        "\n",
        "    # Ensure the scaler is fitted (it was fitted on df above if conditions met)\n",
        "    if df_scaled_data.shape[0] > 0:\n",
        "        last_sequence_scaled = scaler.transform(last_sequence_data[features])\n",
        "        input_for_prediction = np.expand_dims(last_sequence_scaled, axis=0)\n",
        "        prediction_encoded = np.argmax(model.predict(input_for_prediction, verbose=0), axis=1)[0]\n",
        "        prediction_decoded = encoder.inverse_transform([prediction_encoded])[0]\n",
        "        drought_alert = diagnose_drought_stress(last_sequence_data) # Pass the sequence data for diagnosis\n",
        "        fungal_alert = diagnose_fungal_risk(last_sequence_data)     # Pass the sequence data for diagnosis\n",
        "    else:\n",
        "        prediction_decoded = \"Not enough data for scaling/encoding\"\n",
        "        drought_alert = \"Not enough data for diagnosis\"\n",
        "        fungal_alert = \"Not enough data for diagnosis\"\n",
        "\n",
        "\n",
        "# --- Dynamic data for LLM ---\n",
        "llm_soil_moisture = \"Unknown\"\n",
        "llm_weather_condition = None\n",
        "smart_insight = \"Not enough data for AI insight for this field or issues with GEE/LLM API.\"\n",
        "\n",
        "if len(df) > 0: # Ensure df is not empty after filtering\n",
        "    # Get the latest data point from the selected date range\n",
        "    current_data_point = df.iloc[-1]\n",
        "    current_soil_moisture = current_data_point['simulated_soil_moisture']\n",
        "    current_leaf_wetness = current_data_point['simulated_leaf_wetness']\n",
        "    current_temp = current_data_point['Temperature_C']\n",
        "    current_ndvi = current_data_point['ndvi_normalized']\n",
        "\n",
        "    # Categorize soil moisture\n",
        "    if current_soil_moisture < 25:\n",
        "        llm_soil_moisture = \"Low\"\n",
        "    elif current_soil_moisture < 50:\n",
        "        llm_soil_moisture = \"Medium\"\n",
        "    else:\n",
        "        llm_soil_moisture = \"High\"\n",
        "\n",
        "    # Infer weather condition (simple heuristic)\n",
        "    if current_leaf_wetness > 80 and current_soil_moisture > 50:\n",
        "        llm_weather_condition = \"Rainy\"\n",
        "    elif current_soil_moisture < 30 and current_temp > 28:\n",
        "        llm_weather_condition = \"Sunny and Dry\"\n",
        "    else:\n",
        "        llm_weather_condition = \"Normal/Partly Cloudy\"\n",
        "\n",
        "    # Generate AI Insight\n",
        "    smart_insight = get_smart_insight_enhanced(\n",
        "        field_id=selected_field,\n",
        "        stage=prediction_decoded,\n",
        "        max_ndvi=current_ndvi,\n",
        "        weather_condition=llm_weather_condition,\n",
        "        soil_moisture=llm_soil_moisture\n",
        "    )\n",
        "\n",
        "# --- Main Dashboard Area ---\n",
        "col1, col2 = st.columns(2)\n",
        "\n",
        "with col1:\n",
        "    st.header(f\"Analysis for {selected_field} (as of {selected_date.strftime('%Y-%m-%d')})\")\n",
        "    st.subheader(\"Current Predicted Growth Stage:\")\n",
        "    st.metric(label=\"Stage\", value=prediction_decoded)\n",
        "\n",
        "    st.subheader(\"Smart Diagnosis Alerts:\")\n",
        "    # Ensure diagnostics only show for the relevant sequence, not the whole filtered df\n",
        "    if drought_alert and \"Not enough data\" not in drought_alert:\n",
        "        st.error(drought_alert)\n",
        "    elif len(df) >= sequence_length:\n",
        "        st.success(\"âœ… No drought stress detected.\")\n",
        "    else:\n",
        "        st.info(f\"Not enough data (need {sequence_length} weeks) to diagnose drought stress for {selected_date.strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "    if fungal_alert and \"Not enough data\" not in fungal_alert:\n",
        "        st.error(fungal_alert)\n",
        "    elif len(df) >= sequence_length:\n",
        "        st.success(\"âœ… No significant fungal disease risk detected.\")\n",
        "    else:\n",
        "        st.info(f\"Not enough data (need {sequence_length} weeks) to diagnose fungal risk for {selected_date.strftime('%Y-%m-%d')}.\")\n",
        "\n",
        "    st.subheader(\"AI-Powered Agronomic Insight:\")\n",
        "    if smart_insight:\n",
        "        st.markdown(f\"\"\"\n",
        "        <div style=\"background-color:#E8F5E9; padding:15px; border-radius:10px; border-left: 5px solid #4CAF50; color: #000000;\">\n",
        "            {smart_insight}\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "    else:\n",
        "        st.info(\"AI insight could not be generated.\")\n",
        "\n",
        "with col2:\n",
        "    st.header(\"Visual Analysis\")\n",
        "    st.subheader(\"In-Field Health Map\")\n",
        "\n",
        "    # --- Dynamic GEE Health Map Integration ---\n",
        "    map_image_path = generate_dynamic_health_map(selected_field, selected_date)\n",
        "    if map_image_path:\n",
        "        st.image(map_image_path, caption=f'Dynamic Health Map for {selected_field} on {selected_date.strftime(\"%Y-%m-%d\")}')\n",
        "        # Clean up the generated image file after displaying (optional, but good practice)\n",
        "        try:\n",
        "            os.remove(map_image_path)\n",
        "        except OSError:\n",
        "            pass # Ignore if file doesn't exist for some reason\n",
        "    else:\n",
        "        st.info(\"Dynamic health map could not be generated for this field and date.\")\n",
        "\n",
        "    # New: Growth Stage Trend Plot\n",
        "    st.subheader(\"Growth Stage Trend\")\n",
        "    show_growth_stage_trend = st.checkbox('Show Historical Growth Stage Trend', value=True) # Checkbox in sidebar\n",
        "    if show_growth_stage_trend:\n",
        "        if not df_filtered_by_field.empty:\n",
        "            fig_growth_stage = px.line(df_filtered_by_field, x='Date', y='growth_stage', color_discrete_sequence=px.colors.qualitative.Plotly,\n",
        "                                       title=f'Historical Growth Stages for {selected_field}')\n",
        "            fig_growth_stage.update_layout(yaxis_title='Growth Stage')\n",
        "            st.plotly_chart(fig_growth_stage, use_container_width=True)\n",
        "        else:\n",
        "            st.info(f\"No historical growth stage data available for {selected_field}.\")\n",
        "\n",
        "    # New: Key Environmental Factors Trend Plot\n",
        "    st.subheader(\"Key Environmental Factors Trend\")\n",
        "    if show_environmental_factors_trend and selected_environmental_factors:\n",
        "        if not df_filtered_by_field.empty and all(factor in df_filtered_by_field.columns for factor in selected_environmental_factors):\n",
        "            fig_env_factors = px.line(df_filtered_by_field, x='Date', y=selected_environmental_factors,\n",
        "                                      title=f'Environmental Factors for {selected_field}')\n",
        "            st.plotly_chart(fig_env_factors, use_container_width=True)\n",
        "        else:\n",
        "            st.info(\"Please select environmental factors to display or check if data is available.\")\n",
        "    elif show_environmental_factors_trend and not selected_environmental_factors:\n",
        "        st.info(\"Please select at least one environmental factor from the sidebar.\")\n",
        "\n",
        "    st.subheader(\"Comparative NDVI Trend Across All Fields (Current Season)\")\n",
        "    # Filter data for the current season (year of selected_date) across ALL fields\n",
        "    df_season_all_fields = df_full[df_full['Date'].dt.year == selected_date.year]\n",
        "\n",
        "    if not df_season_all_fields.empty:\n",
        "        fig_ndvi_comparative = px.line(df_season_all_fields, x='Date', y='ndvi_normalized', color='field_id',\n",
        "                                title=f'Comparative NDVI Trend for All Fields in {selected_date.year}')\n",
        "        st.plotly_chart(fig_ndvi_comparative, use_container_width=True)\n",
        "    else:\n",
        "        st.info(f\"No NDVI data available for any field for the season {selected_date.year}.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_6H-TD1qDB5",
        "outputId": "a7d6e676-e55d-48b5-cacf-38e8df0c8fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Your Streamlit app is live! Click the link to view: NgrokTunnel: \"https://649be3713e91.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.201.143.202:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-11-29 08:15:21.489531: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1764404121.541501   31912 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1764404121.556664   31912 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1764404121.603298   31912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764404121.603370   31912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764404121.603381   31912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1764404121.603389   31912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-11-29 08:15:34.800664: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "2025-11-29 08:16:00.848 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-11-29 08:16:00.944 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-11-29 08:16:05.761 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "2025-11-29 08:16:05.819 Please replace `use_container_width` with `width`.\n",
            "\n",
            "`use_container_width` will be removed after 2025-12-31.\n",
            "\n",
            "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# This cell launches the app and creates the public link.\n",
        "# It might run for a long time, which is normal.\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Open a tunnel to the streamlit port 8501\n",
        "public_url = ngrok.connect(8501);\n",
        "print(f\"âœ… Your Streamlit app is live! Click the link to view: {public_url}\");\n",
        "\n",
        "# Run the streamlit app\n",
        "!streamlit run app.py --server.runOnSave true"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}